[{"authors":["admin"],"categories":null,"content":"I\u0026rsquo;m a Statistician, currently working as part of a statistics group supporting an engineering research lab. My main research interests are spatial statistics and statistical computing, but I also enjoy \u0026ldquo;playing in everyone else\u0026rsquo;s backyard\u0026rdquo; (i.e. collaborations). Some of the backyards I\u0026rsquo;ve played in - from my previous gig as an assistant professor at West Virginia University - include Forensics and medical applications.\n","date":1590883200,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1590883200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I\u0026rsquo;m a Statistician, currently working as part of a statistics group supporting an engineering research lab. My main research interests are spatial statistics and statistical computing, but I also enjoy \u0026ldquo;playing in everyone else\u0026rsquo;s backyard\u0026rdquo; (i.e. collaborations). Some of the backyards I\u0026rsquo;ve played in - from my previous gig as an assistant professor at West Virginia University - include Forensics and medical applications.","tags":null,"title":"Casey Jelsema","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026#34;Courses\u0026#34; url = \u0026#34;courses/\u0026#34; weight = 50 Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026#34;Docs\u0026#34; url = \u0026#34;docs/\u0026#34; weight = 50 Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":[],"content":"The short version When encountering scientific claims - or really any objective claim - it can be difficult to know what to believe, especially when there seems to be conflicting stories. In the world of COVID-19 shutdowns and stay-at-home orders, it can be hard to parse through the deluge of information and figure out what\u0026rsquo;s going on. The following set of questions can serve as a sort of \u0026ldquo;smell test\u0026rdquo; to get an initial sense of the validity of the claims at hand.\n Who or what is the source? Why should we listen to them? Are they citing sources or presenting data? What is their expertise? Are the claims extravagant? Does the source have a known bias?  The long version The COVID-19 pandemic rather abruptly thrust science into peoples\u0026rsquo; faces. In a very short timeframe we went from ordinary news, to \u0026ldquo;There\u0026rsquo;s an outbreak in China,\u0026rdquo; to \u0026ldquo;It\u0026rsquo;s spreading worldwide,\u0026rdquo; to \u0026ldquo;It\u0026rsquo;s here and governors are issuing expansive shutdowns and stay-at-home orders.\u0026rdquo; People were suddenly inundated statistical claims and scientific results (as of July 20, 2020, Nature reported there to be 65,470 scientific papers on COVID-19).\nThe problem is that most people are not statisticians or epidemiologists. Most people are not microbiologists, immunologists, or researchers in a slew of other biomedical fields. Most people are not highly trained in research methods and reading the results.\nA constantly updating deluge of technical information that most people have a difficult time understanding creates a prime situation for misinformation, confirmation bias, and conspiracy theories to propagate. We have seen much of this in the course of the COVID-19 pandemic.\nMy intent in this post is to give a few questions you can ask yourself to assess new information - whether it\u0026rsquo;s a scientific article, a news report, or a post on social media. My set of questions is not exhaustive, but represents a fairly good first pass to sort out what is reliable from what is not. Many of the claims that I\u0026rsquo;ve seen posted across social media fail at least one, if not several or all, of the questions on my list.\nQuestion 1: Who or what is the source, and why should we listen to them? When it comes to objective and scientific claims, I think there are two main things to pay attention to: Evidence and expertise. If you can\u0026rsquo;t identify at least one of these things, there is no reason to believe the source. It doesn\u0026rsquo;t matter if something \u0026ldquo;just makes sense\u0026rdquo; or if someone\u0026rsquo;s \u0026ldquo;gut feeling\u0026rdquo; leans a certain way. That\u0026rsquo;s valid for subjective matters, but not for assessing scientific results.\nSo from the get-go, ask yourself: Is there evidence being cited, or does this person have expertise?\nQuestion 2: Are they providing evidence? There is a saying among statisticians: \u0026ldquo;In God we trust, all others bring data.\u0026rdquo; Evidence reigns supreme. In general, I\u0026rsquo;d rank the \u0026ldquo;reliability\u0026rdquo; of claims as:\n Expert who is citing evidence: Very high. Expert speaking about their field, but not citing evidence: High, but with reservations. Even experts can be mistaken, or have lost their credibility as did the former scientist featured in \u0026ldquo;Plandemic.\u0026rdquo; Non-expert citing evidence: Good, but with reservations. Non-expert without evidence: Low, no reason to give them the time of day.  The reason I\u0026rsquo;d put a non-expert with evidence as \u0026ldquo;Good, but with reservations\u0026rdquo; is because evidence does not necessarily speak for itself. Someone without expertise does not necessarily know what is important to consider. They may point to one set of data, but be missing a critical concept, or not realize that the data are unreliable for one reason or another. Someone with appropriate expertise is in a better position to know what is important to consider, and to interpret the available evidence.\nAnother saying - called Hitchens\u0026rsquo;s razor - is relevant here: \u0026ldquo;What can be asserted without evidence can also be dismissed without evidence.\u0026rdquo;\nQuestion 3: What is their expertise? Now, just because someone has expertise doesn\u0026rsquo;t mean they are automatically a reliable source. The field of expertise also matters. I myself am a statistician, I can speak to statistical matters. Statistics is somewhat unique in that it is the language of science, permeating the scientific endeavor: Researchers need to communicate their results, and that communication typically involves statistical experimentation and analysis. As John Tukey put it, statisticians \u0026ldquo;get to play in everyone\u0026rsquo;s backyard\u0026rdquo;, meaning we get exposed to and pick up a bit of various topics. We might not be experts in the field, but we can usually understand and assess the results.\nBut you shouldn\u0026rsquo;t ask me to describe why or how a given protein does what it does. You shouldn\u0026rsquo;t ask me to describe the mechanism by which a medication functions. Or why some molecule will or will not react with another, or how the gravity of the sun and planets interact with each other in the solar system. Similarly, you should not ask me to run electrical wiring for a house or repair a car engine.\nMy point here is that specialty matters. Nobody is an expert in all things. Some fields are closely related, so an expert in one may be highly competent in another, but many fields are exceedingly diverse. So it\u0026rsquo;s important to keep someone\u0026rsquo;s specialty in mind when listening to what they have to say.\nI\u0026rsquo;ve seen a number of times people quote medical doctors when talking about COVID-19. That\u0026rsquo;s perfectly fine, when the topic is about clinical matters. Just as being a statistician doesn\u0026rsquo;t make me an expert in medicine, having an MD doesn\u0026rsquo;t make one an expert in statistics or epidemiology. Just because a topic is related to the medical field does not make medical doctors the foremost experts.\nOne job that I\u0026rsquo;ve held has been as a professor in a biostatistics department. I\u0026rsquo;ve collaborated with MDs and residents, and I\u0026rsquo;ve taught aspiring doctors. Some of the doctors had a solid grasp of statistical methods. Most did not. Fewer still should conduct their own statistical analysis. The students aiming for med school often took one or two courses in statistics, not enough to offer a comprehensive understanding statistics, much less the ability to properly conduct statistical analysis. Some were diligent students that probably retained the ideas of the course past the end of the semester. But most were (due to the competitiveness of med school applications) were hyper-focused on grades rather than understanding, and likely retained little if anything that we talked about after the final exam.\nTo be sure, there are some MDs who are excellent researchers, Dr. Anthony Fauci is a prime example. But when talking about a statistical or epidemiological analysis an MD is not automatically an expert, they are likely talking outside of their domain of expertise.\nQuestion 4: Are the claims extravagant? As Carl Sagan said, \u0026ldquo;Extraordinary claims require extraordinary evidence.\u0026rdquo; There are sometimes dramatic breakthroughs, but usually results are much more mundane or incremental in nature. If you see a headline or claim that seems too good to be true, it\u0026rsquo;s probably either misleading clickbait, misinformation, or conspiracy.\nQuestion 5: Does the source have a known bias? Biased sources are likely to selectively interpret results, and either overlook or deliberately obscure flaws. That\u0026rsquo;s why a lot of research has a statement about funding sources. Remember those doctors from Bakersfield, California? They run a private urgent care facilities. They had an enormous conflict of interest: Personal profit. If they did not have that incredible bias, they may have been more reserved about their comments, and perhaps noticed the dramatic statistical and scientific errors they were making, and for which they were condemned by two major medical associations, the American College of Emergency Physicians and the American Academy of Emergency Medicine.\nA financial bias is not the only bias out there. Various news outlets have a strong bias, and will omit certain facts, or selectively choose stories that spin a particular narrative. If a source is known to have a strong bias (be it right or left), then caution should be exercised in assessing the claims being made. This goes doubly so when the source itself acknowledges that it is biased, which ties back to the first question: Who is the source and why should we believe them? If the source admits they are biased, we should be skeptical of anything they have to say.\n","date":1595548800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595629084,"objectID":"92f5a8417c8fe0fa6ead5a2fd18b57db","permalink":"/post-other/a-scientific-smell-test/","publishdate":"2020-07-24T00:00:00Z","relpermalink":"/post-other/a-scientific-smell-test/","section":"post-other","summary":"The short version When encountering scientific claims - or really any objective claim - it can be difficult to know what to believe, especially when there seems to be conflicting stories. In the world of COVID-19 shutdowns and stay-at-home orders, it can be hard to parse through the deluge of information and figure out what\u0026rsquo;s going on. The following set of questions can serve as a sort of \u0026ldquo;smell test\u0026rdquo; to get an initial sense of the validity of the claims at hand.","tags":["covid","coronavirus","science","evidence"],"title":"A Scientific Smell Test","type":"post-other"},{"authors":[],"categories":["general"],"content":"Welcome! If you\u0026rsquo;ve found your way to this page \u0026hellip; well, I\u0026rsquo;m more than a little surprised. This is my personal website. I\u0026rsquo;m not entirely sure what I\u0026rsquo;ll be doing here. My plan at the moment is to use it mainly for:\n Listing professional things like publications independently of my place of employment. Host the slides for talks or workshops that I give.  I may have some posts (is that \u0026lsquo;blogging\u0026rsquo;? Save me!) about topics that pique my interest. This would likely be my thoughts on some bit of Statistics or science that came across my screen.\nI\u0026rsquo;ve been talking about science and statistics in the context of COVID-19 on social media for a while now. I may transition some of that here, since social media isn\u0026rsquo;t usually conducive to the long-form comments I make often enough.\n","date":1594771200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594839175,"objectID":"3b462785c865e5125b0dd0f932deec72","permalink":"/post-other/welcome-to-my-site/","publishdate":"2020-07-15T00:00:00Z","relpermalink":"/post-other/welcome-to-my-site/","section":"post-other","summary":"Welcome! If you\u0026rsquo;ve found your way to this page \u0026hellip; well, I\u0026rsquo;m more than a little surprised. This is my personal website. I\u0026rsquo;m not entirely sure what I\u0026rsquo;ll be doing here. My plan at the moment is to use it mainly for:\n Listing professional things like publications independently of my place of employment. Host the slides for talks or workshops that I give.  I may have some posts (is that \u0026lsquo;blogging\u0026rsquo;?","tags":["greetings","welcome"],"title":"Welcome to my site","type":"post-other"},{"authors":["Casey Jelsema","Rajib Paul","Joseph W McKean"],"categories":["publication","methods"],"content":"","date":1590883200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590883200,"objectID":"89aa3b96937486d2635c159123cc612d","permalink":"/publication/2020-robust-v/","publishdate":"2020-04-01T00:00:00Z","relpermalink":"/publication/2020-robust-v/","section":"publication","summary":"For large datasets, spatial covariances are often modeled using basis functions and covariance of a reduced dimensional latent spatial process. For skewed data, likelihood based approaches with Gaussian assumption may not lead to faithful inference. Any $L_{2}$ norm based estimation is susceptible to long tails and outliers due to contamination. Our method is based on an empirical binned covariance matrix using the median absolute deviation and minimizes $L_{1}$ norm between empirical covariance and the model covariance. The consistency of the proposed estimate is established theoretically. The improvement is demonstrated using simulated data and cloud data obtained from NASA's Terra satellite.","tags":["spatial"],"title":"Robust estimation of reduced rank models to large spatial datasets","type":"publication"},{"authors":[],"categories":["r package"],"content":"CLME stands for Constrained Linear Mixed Effects. I wrote this R package (CRAN link) during my postdoctoral work at NIEHS.\nThe fundamental idea is similar to the Jonckheere–Terpstra or any other test for ordered alternatives: If the treatment groups are ordinal, then a trend of some sort may be of interest. If a researcher has such a hypothesis, they can not only test for the ordered alternative, but they can constrain the estimation to respect the order from the alternative hypothesis. This results in getting more power than a comparable test that does not impose constraints or test for an order (e.g., ANOVA).\nFeel free to check out the github repository. There are a variety of improvements I\u0026rsquo;d like to make, including cleaning up my code, removing dependancies, and adding some features. Just need time to get to them. If you\u0026rsquo;d like to join, give me a shout!\nDisclaimer: This is really just a post to get something into the \u0026ldquo;Project\u0026rdquo; space of my website. I\u0026rsquo;ll probably modify this post later to add clarity.\n","date":1565740800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565797783,"objectID":"1cf66225e7593c17a980f29de3004b4b","permalink":"/project/clme/","publishdate":"2019-08-14T00:00:00Z","relpermalink":"/project/clme/","section":"project","summary":"CLME stands for Constrained Linear Mixed Effects. I wrote this R package (CRAN link) during my postdoctoral work at NIEHS.\nThe fundamental idea is similar to the Jonckheere–Terpstra or any other test for ordered alternatives: If the treatment groups are ordinal, then a trend of some sort may be of interest. If a researcher has such a hypothesis, they can not only test for the ordered alternative, but they can constrain the estimation to respect the order from the alternative hypothesis.","tags":["package","order restricted inference","bootstrap"],"title":"CLME","type":"project"},{"authors":[],"categories":["lecture","talk"],"content":"\rThe slides for my Introduction to Spatial Data (geared for non-Statisticians) can be found here:\nhttps://jelsema.github.io/presentations/2019-intro-spatial/intro_spatial.html#1\n","date":1565740800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565794885,"objectID":"7484acca2de3c888eb0a9ddec9379035","permalink":"/talk/wvu-bios-604-intro-to-spatial/","publishdate":"2019-08-14T00:00:00Z","relpermalink":"/talk/wvu-bios-604-intro-to-spatial/","section":"talk","summary":"The slides for my Introduction to Spatial Data (geared for non-Statisticians) can be found here:\nhttps://jelsema.github.io/presentations/2019-intro-spatial/intro_spatial.html#1","tags":["spatial","intro"],"title":"WVU BIOS 604 Intro to Spatial","type":"talk"},{"authors":["Casey Jelsema","Richard Kwok","Shyamal Peddada"],"categories":["publication","methods"],"content":"","date":1556582400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556582400,"objectID":"fd1c3abfdd33965446ec4475cad4126e","permalink":"/publication/2019-threshold-knots/","publishdate":"2019-07-30T00:00:00Z","relpermalink":"/publication/2019-threshold-knots/","section":"publication","summary":"Large spatial datasets are typically modelled through a small set of knot locations; often these locations are specified by the investigator by arbitrary criteria. Existing methods of estimating the locations of knots assume their number is known a priori, or are otherwise computationally intensive. We develop a computationally efficient method of estimating both the location and number of knots for spatial mixed effects models. Our proposed algorithm, Threshold Knot Selection (TKS), estimates knot locations by identifying clusters of large residuals and placing a knot in the centroid of those clusters. We conduct a simulation study showing TKS in relation to several comparable methods of estimating knot locations. Our case study utilizes data of particulate matter concentrations collected during the course of the response and clean-up effort from the 2010 *Deepwater Horizon* oil spill in the Gulf of Mexico.","tags":["spatial"],"title":"Threshold knot selection for large-scale spatial models with applications to the Deepwater Horizon disaster","type":"publication"},{"authors":["Eric Law","Keith Morris","Casey Jelsema"],"categories":["publication","methods"],"content":"","date":1529280000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1529280000,"objectID":"11de56111c7b98c52114236295bf78e2","permalink":"/publication/2018-test-fire2/","publishdate":"2019-07-30T00:00:00Z","relpermalink":"/publication/2018-test-fire2/","section":"publication","summary":"The Association of Firearm and Toolmark Examiners recommends a minimum of two test fires be performed when an unknown firearm is submitted to a laboratory prior to doing a comparison with a cartridge case collected from a crime scene. Limited research has been performed to determine how many test fires are necessary to be representative of the match distribution of a firearm. Various makes and models of firearms comprising five calibers were tested using a hybrid equivalence test to determine how many cartridge cases were required to represent the match distribution of an unknown firearm based on both breech face and firing pin correlation scores from an IBIS® Heritage^(TM) System. The same general trend was observed for each caliber of firearm where the equivalence percentage increased from 10 to 30 cartridge cases. Overall, 15 cartridge cases are sufficient for above an 80% probability of representing the full match distribution for an unknown firearm. To approach full equivalence, 25 cartridge cases are enough because 30 cartridge cases were not found to be significantly higher in equivalence percentage for any caliber of firearm tested.","tags":["monte carlo","equivalence testing","forensics","test fires"],"title":"Determining the number of test fires needed to represent the variability present within firearms of various calibers","type":"publication"},{"authors":["Ori Davidov","Casey Jelsema","Shyamal Peddada"],"categories":["publication","methods"],"content":"","date":1522540800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1522540800,"objectID":"daa2d98e4f42f496756703976902fb26","permalink":"/publication/2018-osin/","publishdate":"2019-07-30T00:00:00Z","relpermalink":"/publication/2018-osin/","section":"publication","summary":"There are many applications in which a statistic follows, at least asymptotically, a normal distribution with a singular or nearly singular variance matrix. A classic example occurs in linear regression models under multicollinearity but there are many more such examples. There is well-developed theory for testing linear equality constraints when the alternative is two-sided and the variance matrix is either singular or nonsingular. In recent years, there is considerable, and growing, interest in developing methods for situations in which the estimated variance matrix is nearly singular. However, there is no corresponding methodology for addressing one-sided, that is, constrained or ordered alternatives. In this article, we develop a unified framework for analyzing such problems. Our approach may be viewed as the trimming or winsorizing of the eigenvalues of the corresponding variance matrix. The proposed methodology is applicable to a wide range of scientific problems and to a variety of statistical models in which inequality constraints arise. We illustrate the methodology using data from a gene expression microarray experiment obtained from the NIEHS’ Fibroid Growth Study. Supplementary materials for this article are available online.","tags":["order restricted inference","bootstrap","singular"],"title":"Testing for Inequality Constraints in Singular Models by Trimming or Winsorizing the Variance Matrix","type":"publication"},{"authors":["Amy Hessl","Kevin Anchukaitis","Casey Jelsema","Benjamin Cook","Oyunsanaa Byambasuren","Caroline Leland","Baatarbileg Nachin","Neil Pederson","Hanqin Tian","Laia Andreu Hayles"],"categories":["publication","collaborative"],"content":"","date":1520985600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1520985600,"objectID":"ef5f07c837121252d69a8f0686615cb5","permalink":"/publication/2018-mongolia-drought/","publishdate":"2019-07-30T00:00:00Z","relpermalink":"/publication/2018-mongolia-drought/","section":"publication","summary":"The severity of recent droughts in semiarid regions is increasingly attributed to anthropogenic climate change, but it is unclear whether these moisture anomalies exceed those of the past and how past variability compares to future projections. On the Mongolian Plateau, a recent decade-long drought that exceeded the variability in the instrumental record was associated with economic, social, and environmental change. We evaluate this drought using an annual reconstruction of the Palmer Drought Severity Index (PDSI) spanning the last 2060 years in concert with simulations of past and future drought through the year 2100 CE. We show that although the most recent drought and pluvial were highly unusual in the last 2000 years, exceeding the 900-year return interval in both cases, these events were not unprecedented in the 2060-year reconstruction, and events of similar duration and severity occur in paleoclimate, historical, and future climate simulations. The Community Earth System Model (CESM) ensemble suggests a drying trend until at least the middle of the 21st century, when this trend reverses as a consequence of elevated precipitation. Although the potential direct effects of elevated CO2 on plant water use efficiency exacerbate uncertainties about future hydroclimate trends, these results suggest that future drought projections for Mongolia are unlikely to exceed those of the last two millennia, despite projected warming.","tags":["copula","geography","drought","mongolia"],"title":"Past and future drought in Mongolia","type":"publication"},{"authors":["Eric Law","Keith Morris","Casey Jelsema"],"categories":["publication","methods"],"content":"","date":1493769600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493769600,"objectID":"6160d3ede8397d566b4b0f1ba430cd2f","permalink":"/publication/2017-test-fire1/","publishdate":"2019-07-30T00:00:00Z","relpermalink":"/publication/2017-test-fire1/","section":"publication","summary":"Many studies have been performed in recent years in the field of firearm examination with the goal of providing an objective method for comparisons of fired cartridge cases. No published research to support the number of test fires needed to represent the variability present within the impressions left on a cartridge case could be found. When a suspect firearm is submitted to a firearm examiner, typically two to four test fires are performed. The recovered cartridge cases are compared to each other to determine which characteristics from the firearm are reproducing, and then compared to any cartridge cases collected at a crime scene. The aim of this research was to determine the number of test fires examiners should perform when a suspect firearm is submitted to the lab to balance cartridge case acquisition time with performance accuracy. Each firearm in the IBIS® database at West Virginia University® is represented by approximately 100 fired cartridge case entries. Random samples of cartridge cases were taken separately from the breech face match score and firing pin match score lists. This subset was compared to the total match distribution of the firearm using a hybrid equivalence test to determine if the subset of similarity scores were statistically equivalent to the larger distribution of scores. For the sampled distribution to remain above 80% equivalent to the match distribution, a minimum of 15 cartridge cases should be used to model the match distribution, based on IBIS® scores. Thirty cartridge cases is a conservative estimate, allowing one to determine that the location and dispersion of the match and sampling distributions are equivalent with nearly 100% probability.","tags":["monte carlo","equivalence testing","forensics","test fires"],"title":"Determining the number of test fires needed to represent the variability present within 9mm Luger firearms","type":"publication"},{"authors":["Casey Jelsema","Shyamal Peddada"],"categories":["publication","methods"],"content":"","date":1479513600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1479513600,"objectID":"b39d1577f8cf960898d166be326f8ad4","permalink":"/publication/2016-clme/","publishdate":"2019-07-30T00:00:00Z","relpermalink":"/publication/2016-clme/","section":"publication","summary":"In many applications researchers are typically interested in testing for inequality constraints in the context of linear fixed effects and mixed effects models. Although there exists a large body of literature for performing statistical inference under inequality constraints, user friendly statistical software implementing such methods is lacking, especially in the context of linear fixed and mixed effects models. In this article we introduce **CLME**, a package in the **R** language that can be used for testing a broad collection of inequality constraints. It uses residual bootstrap based methodology which is reasonably robust to non-normality as well as heteroscedasticity. The package is illustrated using two data sets. The package also contains a graphical user interface built using the shiny package.","tags":["order restricted inference","bootstrap"],"title":"CLME An R package for linear mixed effects models under inequality constraints","type":"publication"},{"authors":["Thomas (Joost) Van't Erve","Fred Lih","Casey Jelsema","Leesa Deterding","Thomas Eling","Ronald Mason","Maria Kadiiska"],"categories":["publication","collaborative"],"content":"","date":1464739200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1464739200,"objectID":"d9c3553108ffc3099a82e9d384d547fc","permalink":"/publication/2016-joost/","publishdate":"2019-07-30T00:00:00Z","relpermalink":"/publication/2016-joost/","section":"publication","summary":"Oxidative stress is elevated in numerous environmental exposures and diseases. Millions of dollars have been spent to try to ameliorate this damaging process using anti-oxidant therapies. Currently, the best accepted biomarker of oxidative stress is the lipid oxidation product 8-iso-prostaglandin F2α (8-iso-PGF2α), which has been measured in over a thousand human and animal studies. 8-iso-PGF2α generation has been exclusively attributed to nonenzymatic chemical lipid peroxidation (CLP). However, 8-iso-PGF2α can also be produced enzymatically by prostaglandin-endoperoxide synthases (PGHS) in vivo. When failing to account for PGHS-dependent generation, 8-iso-PGF2α cannot be interpreted as a selective biomarker of oxidative stress. We investigated the formation of 8-iso-PGF2α in rats exposed to carbon tetrachloride (CCl4) or lipopolysaccharide (LPS) using the 8-iso-PGF2α/PGF2α ratio to quantitatively determine the source(s) of 8-iso-PGF2α. Upon exposure to a 120mg/kg dose of CCl4, the contribution of CLP accounted for only 55.6±19.4% of measured 8-iso-PGF2α, whereas in the 1200mg/kg dose, CLP was the predominant source of 8-iso-PGF2α (86.6±8.0% of total). In contrast to CCl4, exposure to 0.5mg/kg LPS was characterized by a significant increase in both the contribution of PGHS (59.5±7.0) and CLP (40.5±14.0%). In conclusion, significant generation of 8-iso-PGF2α occurs through enzymatic as well as chemical lipid peroxidation. The distribution of the contribution is dependent on the exposure agent as well as the dose. The 8-iso-PGF2α/PGF2α ratio accurately determines the source of 8-iso-PGF2α and provides an absolute measure of oxidative stress in vivo.","tags":["order restricted inference","bootstrap"],"title":"Reinterpreting the best biomarker of oxidative stress: The 8-iso-prostaglandin F2α/prostaglandin F2α ratio shows complex origins of lipid peroxidation biomarkers in animal models","type":"publication"},{"authors":["Rajib Paul","Casey Jelsema","Rex Lau"],"categories":["publication","methods"],"content":"","date":1432166400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1432166400,"objectID":"ad6c9f50ae37a69c5c44e910231fbc56","permalink":"/publication/2015-frssm/","publishdate":"2019-07-30T00:00:00Z","relpermalink":"/publication/2015-frssm/","section":"publication","summary":"In environmental studies, the datasets exhibiting non-Gaussian properties, such as heavier or lighter tails and multimodality, are very common. The research on dealing with such datasets in reduced rank perspectives is very limited. In this chapter, a flexible class of Bayesian reduced rank spatial model is developed that can handle non-Gaussian properties adequately. The spatial model provides the flexibility to deal with such properties through scale mixtures of Gaussian distributions and a two-level marginally noninformative inverse-Wishart prior. A general framework for posterior summaries based on Markov Chain Central Limit Theorem (MCCLT) has been developed and conditions of MCCLT on ergodic averages are theoretically verified. The Monte Carlo standard errors based on MCCLT are computed using batch-mean method. The performance of the proposed model and method are assessed using several simulated datasets and a dataset on daily maximum of total column ozone obtained from National Aeronautic and Space Administration Terra satellite.","tags":["spatial"],"title":"A flexible class of reduced rank spatial models for large non-Gaussian datasets","type":"publication"},{"authors":["Casey Jelsema","Rajib Paul"],"categories":["publication","methods"],"content":"","date":1375142400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1375142400,"objectID":"ed3635726a97802e43fbe1de050476a1","permalink":"/publication/2013-lognormal-coal/","publishdate":"2019-07-30T00:00:00Z","relpermalink":"/publication/2013-lognormal-coal/","section":"publication","summary":"We analyze data on the geochemical make-up of coal samples throughout the state of Illinois. The goal is to estimate the geochemical properties at unobserved locations over a specified region. Multivariate spatial modeling requires characterization of both spatial and cross-spatial covariances. Reduced rank spatial models are popular in analyzing large spatial datasets. We develop a multivariate spatial mixed effects model for log-normal processes and show how to implement with compositional data to predict on point locations, as well as the average prediction over a finite area. We use log-normal kriging for the components of compositional data, and show how to obtain estimates and measures of precision in isometric log-ratio coordinates.","tags":["spatial"],"title":"Lognormal block kriging with applications to goal geology","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8576ec274c98b3831668a172fa632d80","permalink":"/about/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/about/","section":"","summary":"","tags":null,"title":"Experience / Contact","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"/contact/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"Experience / Contact","type":"widget_page"}]